{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b6c5c0",
   "metadata": {},
   "source": [
    "# Machine Learning for Poverty Prediction\n",
    "\n",
    "**Project**: Big Data Pipeline for Poverty Mapping in Sumatra  \n",
    "**Team**: Kelompok 18  \n",
    "**Objective**: Build and evaluate machine learning models to predict poverty levels\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Preparation](#data-prep)\n",
    "2. [Feature Engineering](#feature-engineering)\n",
    "3. [Model Building](#model-building)\n",
    "4. [Model Evaluation](#model-evaluation)\n",
    "5. [Feature Importance Analysis](#feature-importance)\n",
    "6. [Predictions and Insights](#predictions)\n",
    "7. [Model Deployment Preparation](#deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55611615",
   "metadata": {},
   "source": [
    "## 1. Data Preparation {#data-prep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb1dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ðŸ¤– Machine Learning libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d807989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('/data/Profil_Kemiskinan_Sumatera.csv')\n",
    "print(f\"ðŸ“Š Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nColumns in dataset:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "print(\"ðŸ§¹ Data Preprocessing...\")\n",
    "\n",
    "# Handle missing values\n",
    "print(f\"Missing values before: {df.isnull().sum().sum()}\")\n",
    "df_processed = df.dropna()  # For simplicity, dropping rows with missing values\n",
    "print(f\"Missing values after: {df_processed.isnull().sum().sum()}\")\n",
    "print(f\"Rows remaining: {len(df_processed)} ({len(df_processed)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Create a copy for processing\n",
    "df_ml = df_processed.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad775cb6",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering {#feature-engineering}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create poverty level categories for classification\n",
    "def categorize_poverty(poverty_rate):\n",
    "    if poverty_rate < 10:\n",
    "        return 0  # Low\n",
    "    elif poverty_rate < 20:\n",
    "        return 1  # Medium\n",
    "    else:\n",
    "        return 2  # High\n",
    "\n",
    "df_ml['poverty_level'] = df_ml['Persentase Kemiskinan (%)'].apply(categorize_poverty)\n",
    "\n",
    "# Label encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_cols = ['Provinsi', 'Komoditas', 'Golongan Pengeluaran', 'Akses Pendidikan', \n",
    "                   'Fasilitas Kesehatan', 'Akses Air Bersih', 'Kategori Kemiskinan']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df_ml.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_ml[f'{col}_encoded'] = le.fit_transform(df_ml[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "print(\"âœ… Feature engineering completed\")\n",
    "print(f\"New dataset shape: {df_ml.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "print(\"ðŸ”§ Creating additional features...\")\n",
    "\n",
    "# Population density proxy\n",
    "df_ml['pop_log'] = np.log1p(df_ml['Jumlah Penduduk (jiwa)'])\n",
    "\n",
    "# Unemployment to poverty ratio\n",
    "df_ml['unemployment_poverty_ratio'] = df_ml['Tingkat Pengangguran (%)'] / (df_ml['Persentase Kemiskinan (%)'] + 1)\n",
    "\n",
    "# Infrastructure score (combination of access variables)\n",
    "infrastructure_map = {'baik': 3, 'sedang': 2, 'buruk': 1, 'memadai': 3, 'tidak memadai': 1, 'ya': 1, 'tidak': 0}\n",
    "\n",
    "df_ml['education_score'] = df_ml['Akses Pendidikan'].map(infrastructure_map).fillna(0)\n",
    "df_ml['health_score'] = df_ml['Fasilitas Kesehatan'].map({'memadai': 1, 'tidak memadai': 0}).fillna(0)\n",
    "df_ml['water_score'] = df_ml['Akses Air Bersih'].map({'ya': 1, 'tidak': 0}).fillna(0)\n",
    "\n",
    "df_ml['infrastructure_score'] = df_ml['education_score'] + df_ml['health_score'] + df_ml['water_score']\n",
    "\n",
    "print(\"âœ… Additional features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7a8f4",
   "metadata": {},
   "source": [
    "## 3. Model Building {#model-building}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bffea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "feature_cols = ['Tingkat Pengangguran (%)', 'Jumlah Penduduk (jiwa)', 'Konsumsi (per kapita per minggu)',\n",
    "               'Provinsi_encoded', 'Golongan Pengeluaran_encoded', 'pop_log', \n",
    "               'unemployment_poverty_ratio', 'infrastructure_score']\n",
    "\n",
    "# Filter features that exist in the dataset\n",
    "available_features = [col for col in feature_cols if col in df_ml.columns]\n",
    "print(f\"Available features for modeling: {available_features}\")\n",
    "\n",
    "X = df_ml[available_features]\n",
    "y_classification = df_ml['poverty_level']\n",
    "y_regression = df_ml['Persentase Kemiskinan (%)']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target distribution (classification): {y_classification.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for classification\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_classification, test_size=0.2, random_state=42, stratify=y_classification\n",
    ")\n",
    "\n",
    "# Split data for regression\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_regression, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_clf_scaled = scaler.fit_transform(X_train_clf)\n",
    "X_test_clf_scaled = scaler.transform(X_test_clf)\n",
    "\n",
    "X_train_reg_scaled = scaler.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler.transform(X_test_reg)\n",
    "\n",
    "print(\"âœ… Data split and scaled successfully\")\n",
    "print(f\"Training set size: {X_train_clf.shape[0]}\")\n",
    "print(f\"Test set size: {X_test_clf.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4654806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Classification Models\n",
    "print(\"ðŸ”¨ Building Classification Models...\")\n",
    "\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVM': SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "clf_results = {}\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    if name == 'Random Forest':\n",
    "        classifier.fit(X_train_clf, y_train_clf)\n",
    "        y_pred = classifier.predict(X_test_clf)\n",
    "    else:\n",
    "        classifier.fit(X_train_clf_scaled, y_train_clf)\n",
    "        y_pred = classifier.predict(X_test_clf_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_clf, y_pred)\n",
    "    precision = precision_score(y_test_clf, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test_clf, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test_clf, y_pred, average='weighted')\n",
    "    \n",
    "    clf_results[name] = {\n",
    "        'model': classifier,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"F1-Score: {f1:.3f}\")\n",
    "\n",
    "print(\"\\nâœ… Classification models trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a21acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Regression Models\n",
    "print(\"ðŸ”¨ Building Regression Models...\")\n",
    "\n",
    "regressors = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "reg_results = {}\n",
    "\n",
    "for name, regressor in regressors.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    if name == 'Random Forest':\n",
    "        regressor.fit(X_train_reg, y_train_reg)\n",
    "        y_pred = regressor.predict(X_test_reg)\n",
    "    else:\n",
    "        regressor.fit(X_train_reg_scaled, y_train_reg)\n",
    "        y_pred = regressor.predict(X_test_reg_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test_reg, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_reg, y_pred)\n",
    "    \n",
    "    reg_results[name] = {\n",
    "        'model': regressor,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"RÂ²: {r2:.3f}\")\n",
    "\n",
    "print(\"\\nâœ… Regression models trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f542b",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation {#model-evaluation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d09c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Results Comparison\n",
    "print(\"ðŸ“Š CLASSIFICATION MODELS COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "clf_comparison = pd.DataFrame({\n",
    "    'Model': list(clf_results.keys()),\n",
    "    'Accuracy': [clf_results[model]['accuracy'] for model in clf_results],\n",
    "    'Precision': [clf_results[model]['precision'] for model in clf_results],\n",
    "    'Recall': [clf_results[model]['recall'] for model in clf_results],\n",
    "    'F1-Score': [clf_results[model]['f1'] for model in clf_results]\n",
    "})\n",
    "\n",
    "print(clf_comparison.round(3))\n",
    "\n",
    "# Find best classification model\n",
    "best_clf_model = clf_comparison.loc[clf_comparison['F1-Score'].idxmax(), 'Model']\n",
    "print(f\"\\nðŸ† Best Classification Model: {best_clf_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03596d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Results Comparison\n",
    "print(\"ðŸ“Š REGRESSION MODELS COMPARISON\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "reg_comparison = pd.DataFrame({\n",
    "    'Model': list(reg_results.keys()),\n",
    "    'MSE': [reg_results[model]['mse'] for model in reg_results],\n",
    "    'RMSE': [reg_results[model]['rmse'] for model in reg_results],\n",
    "    'RÂ²': [reg_results[model]['r2'] for model in reg_results]\n",
    "})\n",
    "\n",
    "print(reg_comparison.round(3))\n",
    "\n",
    "# Find best regression model\n",
    "best_reg_model = reg_comparison.loc[reg_comparison['RÂ²'].idxmax(), 'Model']\n",
    "print(f\"\\nðŸ† Best Regression Model: {best_reg_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of best models\n",
    "print(f\"\\nðŸ” DETAILED EVALUATION: {best_clf_model} (Classification)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_clf = clf_results[best_clf_model]\n",
    "y_pred_best_clf = best_clf['predictions']\n",
    "\n",
    "# Classification report\n",
    "target_names = ['Low Poverty', 'Medium Poverty', 'High Poverty']\n",
    "print(classification_report(y_test_clf, y_pred_best_clf, target_names=target_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_clf, y_pred_best_clf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title(f'Confusion Matrix - {best_clf_model}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression model evaluation\n",
    "print(f\"\\nðŸ” DETAILED EVALUATION: {best_reg_model} (Regression)\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "best_reg = reg_results[best_reg_model]\n",
    "y_pred_best_reg = best_reg['predictions']\n",
    "\n",
    "# Scatter plot of predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test_reg, y_pred_best_reg, alpha=0.6)\n",
    "plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Poverty Rate (%)')\n",
    "plt.ylabel('Predicted Poverty Rate (%)')\n",
    "plt.title(f'Predictions vs Actual - {best_reg_model}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test_reg - y_pred_best_reg\n",
    "plt.scatter(y_pred_best_reg, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Poverty Rate (%)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Model Performance:\")\n",
    "print(f\"  RMSE: {best_reg['rmse']:.3f}\")\n",
    "print(f\"  RÂ²: {best_reg['r2']:.3f}\")\n",
    "print(f\"  Mean Absolute Error: {np.mean(np.abs(residuals)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706e5b4",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis {#feature-importance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c6a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Random Forest models\n",
    "if 'Random Forest' in clf_results:\n",
    "    rf_clf = clf_results['Random Forest']['model']\n",
    "    feature_importance_clf = pd.DataFrame({\n",
    "        'feature': available_features,\n",
    "        'importance': rf_clf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"ðŸŒ³ FEATURE IMPORTANCE - CLASSIFICATION (Random Forest)\")\n",
    "    print(\"=\" * 55)\n",
    "    print(feature_importance_clf)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance_clf, y='feature', x='importance', palette='viridis')\n",
    "    plt.title('Feature Importance - Classification Model')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'Random Forest' in reg_results:\n",
    "    rf_reg = reg_results['Random Forest']['model']\n",
    "    feature_importance_reg = pd.DataFrame({\n",
    "        'feature': available_features,\n",
    "        'importance': rf_reg.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸŒ³ FEATURE IMPORTANCE - REGRESSION (Random Forest)\")\n",
    "    print(\"=\" * 50)\n",
    "    print(feature_importance_reg)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance_reg, y='feature', x='importance', palette='plasma')\n",
    "    plt.title('Feature Importance - Regression Model')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab72592",
   "metadata": {},
   "source": [
    "## 6. Predictions and Insights {#predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate insights from the best models\n",
    "print(\"ðŸŽ¯ KEY INSIGHTS FROM MACHINE LEARNING MODELS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Classification insights\n",
    "poverty_distribution = pd.Series(y_test_clf).value_counts().sort_index()\n",
    "prediction_distribution = pd.Series(y_pred_best_clf).value_counts().sort_index()\n",
    "\n",
    "print(\"ðŸ“Š Poverty Level Distribution:\")\n",
    "print(f\"   Actual - Low: {poverty_distribution.get(0, 0)}, Medium: {poverty_distribution.get(1, 0)}, High: {poverty_distribution.get(2, 0)}\")\n",
    "print(f\"   Predicted - Low: {prediction_distribution.get(0, 0)}, Medium: {prediction_distribution.get(1, 0)}, High: {prediction_distribution.get(2, 0)}\")\n",
    "\n",
    "# Model accuracy insights\n",
    "print(f\"\\nðŸŽ¯ Model Performance:\")\n",
    "print(f\"   Classification Accuracy: {best_clf['accuracy']:.1%}\")\n",
    "print(f\"   Regression RÂ²: {best_reg['r2']:.3f}\")\n",
    "print(f\"   Average Prediction Error: Â±{best_reg['rmse']:.1f}%\")\n",
    "\n",
    "# Feature insights\n",
    "if 'Random Forest' in clf_results:\n",
    "    top_features = feature_importance_clf.head(3)\n",
    "    print(f\"\\nðŸ”‘ Top 3 Most Important Features:\")\n",
    "    for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "        print(f\"   {i}. {row['feature']}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0bc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict poverty for different scenarios\n",
    "print(\"\\nðŸ”® POVERTY PREDICTION SCENARIOS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create sample scenarios\n",
    "scenarios = {\n",
    "    'Low Risk Area': {\n",
    "        'Tingkat Pengangguran (%)': 5.0,\n",
    "        'infrastructure_score': 4,\n",
    "        'unemployment_poverty_ratio': 0.5\n",
    "    },\n",
    "    'Medium Risk Area': {\n",
    "        'Tingkat Pengangguran (%)': 12.0,\n",
    "        'infrastructure_score': 2,\n",
    "        'unemployment_poverty_ratio': 0.8\n",
    "    },\n",
    "    'High Risk Area': {\n",
    "        'Tingkat Pengangguran (%)': 20.0,\n",
    "        'infrastructure_score': 1,\n",
    "        'unemployment_poverty_ratio': 1.2\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make predictions for scenarios (simplified - using subset of features)\n",
    "for scenario_name, scenario_data in scenarios.items():\n",
    "    print(f\"\\n{scenario_name}:\")\n",
    "    print(f\"  Unemployment Rate: {scenario_data['Tingkat Pengangguran (%)']}%\")\n",
    "    print(f\"  Infrastructure Score: {scenario_data['infrastructure_score']}/5\")\n",
    "    print(f\"  Risk Level: Based on feature analysis, this area shows {'HIGH' if scenario_data['unemployment_poverty_ratio'] > 1.0 else 'MEDIUM' if scenario_data['unemployment_poverty_ratio'] > 0.7 else 'LOW'} poverty risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b57625",
   "metadata": {},
   "source": [
    "## 7. Model Deployment Preparation {#deployment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifacts for deployment\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "print(\"ðŸ’¾ Preparing models for deployment...\")\n",
    "\n",
    "# Save best models\n",
    "model_artifacts = {\n",
    "    'best_classifier': {\n",
    "        'model_name': best_clf_model,\n",
    "        'model': clf_results[best_clf_model]['model'],\n",
    "        'accuracy': clf_results[best_clf_model]['accuracy'],\n",
    "        'features': available_features\n",
    "    },\n",
    "    'best_regressor': {\n",
    "        'model_name': best_reg_model,\n",
    "        'model': reg_results[best_reg_model]['model'],\n",
    "        'r2_score': reg_results[best_reg_model]['r2'],\n",
    "        'rmse': reg_results[best_reg_model]['rmse'],\n",
    "        'features': available_features\n",
    "    },\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': label_encoders\n",
    "}\n",
    "\n",
    "# Create deployment summary\n",
    "deployment_summary = {\n",
    "    'model_info': {\n",
    "        'classification_model': best_clf_model,\n",
    "        'regression_model': best_reg_model,\n",
    "        'features_used': available_features,\n",
    "        'training_date': pd.Timestamp.now().isoformat(),\n",
    "        'data_shape': list(df_ml.shape)\n",
    "    },\n",
    "    'performance': {\n",
    "        'classification_accuracy': float(clf_results[best_clf_model]['accuracy']),\n",
    "        'regression_r2': float(reg_results[best_reg_model]['r2']),\n",
    "        'regression_rmse': float(reg_results[best_reg_model]['rmse'])\n",
    "    },\n",
    "    'feature_importance': feature_importance_clf.to_dict('records') if 'Random Forest' in clf_results else []\n",
    "}\n",
    "\n",
    "print(\"âœ… Model artifacts prepared for deployment\")\n",
    "print(f\"   Classification Model: {best_clf_model} (Accuracy: {clf_results[best_clf_model]['accuracy']:.1%})\")\n",
    "print(f\"   Regression Model: {best_reg_model} (RÂ²: {reg_results[best_reg_model]['r2']:.3f})\")\n",
    "print(f\"   Features: {len(available_features)} features\")\n",
    "print(f\"   Ready for Spark MLlib integration!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model usage example\n",
    "print(\"\\nðŸš€ MODEL USAGE EXAMPLE\")\n",
    "print(\"=\" * 30)\n",
    "print(\"\"\"# Example code for using the trained model in production:\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load('poverty_prediction_model.pkl')\n",
    "scaler = joblib.load('feature_scaler.pkl')\n",
    "\n",
    "# Prepare new data\n",
    "new_data = pd.DataFrame({\n",
    "    'Tingkat Pengangguran (%)': [15.0],\n",
    "    'infrastructure_score': [2],\n",
    "    # ... other features\n",
    "})\n",
    "\n",
    "# Scale features\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(new_data_scaled)\n",
    "probability = model.predict_proba(new_data_scaled)\n",
    "\n",
    "print(f'Predicted poverty level: {prediction[0]}')\n",
    "print(f'Prediction confidence: {max(probability[0]):.2f}')\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ… Machine Learning pipeline completed successfully!\")\n",
    "print(\"ðŸ“Š Models are ready for integration with the big data pipeline.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
